---
title       : Residuals, diagnostics, variation
subtitle    : Regression
author      : Brian Caffo, Jeff Leek, Roger Peng
job         : Johns Hopkins Bloomberg School of Public Health
logo        : bloomberg_shield.png
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
url:
  lib: ../../librariesNew
  assets: ../../assets
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
---
```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F, results='hide'}
# make this an external chunk that can be included in any file
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig_02_04/')

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
runif(1)
```
## The linear model
* Specified as the sum of a bunch of linear effects from the covariance $X_{ik}$ multiplied by the parameters $\beta_j$ 
    * $Y_i =  \sum_{k=1}^p X_{ik} \beta_j + \epsilon_{i}$
* We'll also assume here that the *true* errors are independent and identically distributed normals.
    * $\epsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)$
* Define the *observed* residuals as the difference between the observed data point and the fitted data point,
    * where the fitted data point is the regressors times the fitted beta values:
    * $e_i = Y_i -  \hat Y_i =  Y_i - \sum_{k=1}^p X_{ik} \hat \beta_j$
* Our estimate of residual variation is average squared residual divided by $n-p$:
    * $\hat \sigma^2 = \frac{\sum_{i=1}^n e_i^2}{n-p}$, the $n-p$ so that $E[\hat \sigma^2] = \sigma^2$

---
```{r, fig.height = 5, fig.width = 5}
data(swiss); par(mfrow = c(2, 2))
fit <- lm(Fertility ~ . , data = swiss); plot(fit)
```

---
## Influential, high leverage and outlying points
```{r, fig.height = 5, fig.width=5, echo = FALSE, results='hide'}
n <- 100; x <- rnorm(n); y <- x + rnorm(n, sd = .3)
plot(c(-3, 6), c(-3, 6), type = "n", frame = FALSE, xlab = "X", ylab = "Y")
abline(lm(y ~ x), lwd = 2)
points(x, y, cex = 2, bg = "lightblue", col = "black", pch = 21)
points(0, 0, cex = 2, bg = "darkorange", col = "black", pch = 21)
points(0, 5, cex = 2, bg = "darkorange", col = "black", pch = 21)
points(5, 5, cex = 2, bg = "darkorange", col = "black", pch = 21)
points(5, 0, cex = 2, bg = "darkorange", col = "black", pch = 21)
```

- The orange points were not included in the model.
- The lower left orange point is in the middle of the data, so it would not have influence on the model, nor is it very deviant from the model behavior.
- The upper left orange point wouldn't be very influential because it's in the middle of the X values, but it is aberrant to the model.
- The upper right orange point would be influential, because it's far from the bulk of the data, were it not right on the regression line; it fits the model.
- The lower right orange point would be very influential, pulling the regression line down toward it because it is both outlying and doesn't fit the model. 

---
## Summary of the plot
Calling a point an outlier is vague. 
  * Outliers can be the result of spurious or real processes.
  * Outliers can have varying degrees of influence.
  * Outliers can conform to the regression relationship (i.e being marginally outlying in X or Y, but not outlying given the regression relationship).
* Upper left hand point has low leverage, low influence, outlies in a way not conforming to the regression relationship.
* Lower left hand point has low leverage, low influence and is not to be an outlier in any sense.
* Upper right hand point has high leverage, but chooses not to extert it and thus would have low actual influence by conforming to the regresison relationship of the other points.
* Lower right hand point has high leverage and would exert it if it were included in the fit.

---
## Influence measures
* Do `?influence.measures` to see the full suite of influence measures in stats. The measures include
  * `rstandard` - standardized residuals, residuals divided by their standard deviations)
  * `rstudent` - standardized residuals, residuals divided by their standard deviations, where the ith data point was deleted in the calculation of the standard deviation for the residual to follow a t distribution
  * `hatvalues` - measures of leverage
  * `dffits` - change in the predicted response when the $i^{th}$ point is deleted in fitting the model.
    * measure the influence of points on prediction.
  * `dfbetas` - change in individual coefficients when the $i^{th}$ point is deleted in fitting the model.
    * measure the influence of points on the coefficients; looks at the individual covariance of a point with the coefficient.
  * `cooks.distance` - overall change in the coefficients when the $i^{th}$ point is deleted; looks at all the covariance of the points.
  * `resid` - returns the ordinary residuals
  * `resid(fit) / (1 - hatvalues(fit))` where `fit` is the linear model fit returns the **PRESS** residuals, i.e. the leave one out cross validation residuals - the difference in the response and the predicted response at data point $i$, where it was not included in the model fitting.

---
## How do I use all of these things?
* Be wary of simplistic rules for diagnostic plots and measures. The use of these tools is context specific. It's better to understand what they are trying to accomplish and use them judiciously.
* Not all of the measures have meaningful absolute scales. You can look at them relative to the values across the data.
* They probe your data in different ways to diagnose different problems. 
* Patterns in your residual plots generally indicate some poor aspect of model fit. These can include:
  * Heteroskedasticity (non constant variance).
  * Missing model terms.
  * Temporal patterns (plot residuals versus collection order).
* Residual QQ plots investigate normality of the errors.
* Leverage measures (hat values) can be useful for diagnosing data entry errors.
* Influence measures get to the bottom line, 'how does deleting or including this point impact a particular aspect of the model'.

---
## Case 1
```{r, fig.height=5, fig.width=5, echo=FALSE}
x <- c(10, rnorm(n)); y <- c(10, c(rnorm(n)))
plot(x, y, frame = FALSE, cex = 2, pch = 21, bg = "lightblue", col = "black")
abline(lm(y ~ x))            
```

---
## The code
```
n <- 100; x <- c(10, rnorm(n)); y <- c(10, c(rnorm(n)))
plot(x, y, frame = FALSE, cex = 2, pch = 21, bg = "lightblue", col = "black")
abline(lm(y ~ x))            
```
* The point `c(10, 10)` has created a strong regression relationship where there shouldn't be one.

---
## Showing a couple of the diagnostic values
```{r}
fit <- lm(y ~ x)
round(dfbetas(fit)[1 : 10, 2], 3)
round(hatvalues(fit)[1 : 10], 3)
```

---
## Case 2
```{r, fig.height=5, fig.width=5, echo=FALSE}
x <- rnorm(n); y <- x + rnorm(n, sd = .3)
x <- c(5, x); y <- c(5, y)
plot(x, y, frame = FALSE, cex = 2, pch = 21, bg = "lightblue", col = "black")
fit2 <- lm(y ~ x)
abline(fit2)            
```

---
## Looking at some of the diagnostics
```{r, echo = TRUE}
round(dfbetas(fit2)[1 : 10, 2], 3)
round(hatvalues(fit2)[1 : 10], 3)
```

---
## Example described by Stefanski TAS 2007 Vol 61.
```{r, eval=FALSE}
## Don't everyone hit this server at once.  Read the paper first.
fileURL <- 'http://www4.stat.ncsu.edu/~stefanski/NSF_Supported/Hidden_Images/orly_owl_files/orly_owl_Lin_4p_5_flat.txt'
dir.create("files_02_05")
download.file(fileURL,destfile="files_02_05/orly_owl.txt",method="curl")
```
```{r, fig.height=4, fig.width=4}
dat <- read.table('files_02_05/orly_owl.txt', header = FALSE)
pairs(dat)
```

---
## Got our P-values, should we bother to do a residual plot?
Here we do a standard linear model of the first variable regressing it on everything else (.), and without an intercept (-1). Looking at the coefficients we see a bunch of highly significant p-values.
```{r}
summary(lm(V1 ~ . -1, data = dat))$coef
```

---
## Residual plot
### P-values significant, O RLY?
There's clearly evidence of a pattern in the residuals if we plot the residuals versus the predicted values.

```{r, fig.height=4, fig.width=4, echo = TRUE}
fit <- lm(V1 ~ . - 1, data = dat); plot(predict(fit), resid(fit), pch = '.')
```

---
## Back to the Swiss data
```{r, fig.height = 5, fig.width = 5, echo=TRUE}
data(swiss); par(mfrow = c(2, 2))
fit <- lm(Fertility ~ . , data = swiss); plot(fit)
```
- In a residuals vs predicted values plot, we're looking for any pattern.
- Scale - Location is a plot of a function of the standardized residuals vs the predicted; again, we're looking for any pattern.
- With the Normal Q-Q plot, we're trying to figure out normality of the errors by plotting the theoretical quantiles of the standard normal distribution *vs* the standardized residuals.
- With Residuals vs Leverage, we're looking at the comparison of fit at that point versus potential for influence at that point.
- Also shown in the plot are the names of various provinces of the dataset.
- Try looking at the `dffits()` and `dfbetas()` and `cooks.distance()` for this dataset. Look for whether or not any of the provinces seems influential or has a large effect, and maybe explore those particular points.